postfix: "postprocessing"

seed: 42
precision: 16
accelerator: gpu
devices: 1

dataset_root: /home/aagorodilova_2/PROJECT-Deep_Metric_Learning/CARS196
logs_root: /home/aagorodilova_2/PROJECT-Deep_Metric_Learning/logs/CARS196/
dataframe_name: df_no_bboxes.csv
logs_folder: ${now:%Y-%m-%d_%H-%M-%S}_${postfix}

num_workers: 20
max_epochs: 1000
valid_period: 5
n_queries: 3

# CACHE EMBEDDINGS PRODUCED BY BASELINE FEATURE EXTRACTOR

embeddings_cache_dir: ${dataset_root}

extractor_weights: /home/aagorodilova_2/PROJECT-Deep_Metric_Learning/logs/CARS196/2023-04-16_01-19-44_metric_learning_cars/checkpoints/best.ckpt

extractor:
  name: vit
  args:
    normalise_features: True
    use_multi_scale: False
    weights: ${extractor_weights}
    arch: vits16

transforms_extraction:
  name: norm_resize_hypvit_torch
  args:
    im_size: 224

# TRAIN POSTPROCESSOR

pairwise_model:
  name: multi_query_attn
  args:
    n_heads: 4
    n_query: ${n_queries}

hard_pairs_mining: True

optimizer:
  name: adam
  args:
    lr: 5e-5

scheduling:
  scheduler_interval: epoch
  scheduler_frequency: 1
  scheduler:
    name: cosine_annealing
    args:
      T_max: 1000
      eta_min: 1e-6

sampler:
  name: balance
  args:
    n_labels: 30
    n_instances: 6

transforms_train:
  name: augs_hypvit_torch
  args:
    im_size: 224

# VALIDATE POSTPROCESSOR BY RE-RANKING TOP-N OUTPUTS

batch_size_inference: 128

postprocessor:
  name: multiple_emb
  args:
    top_n: 15
    n_queries: ${n_queries}
    pairwise_model: ${pairwise_model}
    num_workers: ${num_workers}
    batch_size: ${batch_size_inference}
    verbose: True
    use_fp16: True

metric_for_checkpointing: OVERALL/cmc/1
log_images: False

metric_args:
  metrics_to_exclude_from_visualization: [cmc,]
  cmc_top_k: [1]
  map_top_k: [5]
  fmr_vals: [0.01]
  pfc_variance: [0.5, 0.9, 0.99]
  return_only_main_category: True
  visualize_only_main_category: True

# To use neptune you should also specify NEPTUNE_API_TOKEN in
# .env file or via export NEPTUNE_API_TOKEN=...
neptune_project: null

wandb_project: DIPLOMA
wandb_name: train_postprocessor

tags:
  - postprocessing

hydra_dir: ${logs_root}/${logs_folder}/

hydra:
  run:
    dir: ${hydra_dir}
  searchpath:
    - pkg://oml.configs